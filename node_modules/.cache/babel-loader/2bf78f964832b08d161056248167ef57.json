{"ast":null,"code":"var tokenize = require('../tokenizer');\n\nvar TokenStream = require('../common/TokenStream');\n\nvar tokenStream = new TokenStream();\nvar astToTokens = {\n  decorator: function (handlers) {\n    var curNode = null;\n    var prev = {\n      len: 0,\n      node: null\n    };\n    var nodes = [prev];\n    var buffer = '';\n    return {\n      children: handlers.children,\n      node: function (node) {\n        var tmp = curNode;\n        curNode = node;\n        handlers.node.call(this, node);\n        curNode = tmp;\n      },\n      chunk: function (chunk) {\n        buffer += chunk;\n\n        if (prev.node !== curNode) {\n          nodes.push({\n            len: chunk.length,\n            node: curNode\n          });\n        } else {\n          prev.len += chunk.length;\n        }\n      },\n      result: function () {\n        return prepareTokens(buffer, nodes);\n      }\n    };\n  }\n};\n\nfunction prepareTokens(str, nodes) {\n  var tokens = [];\n  var nodesOffset = 0;\n  var nodesIndex = 0;\n  var currentNode = nodes ? nodes[nodesIndex].node : null;\n  tokenize(str, tokenStream);\n\n  while (!tokenStream.eof) {\n    if (nodes) {\n      while (nodesIndex < nodes.length && nodesOffset + nodes[nodesIndex].len <= tokenStream.tokenStart) {\n        nodesOffset += nodes[nodesIndex++].len;\n        currentNode = nodes[nodesIndex].node;\n      }\n    }\n\n    tokens.push({\n      type: tokenStream.tokenType,\n      value: tokenStream.getTokenValue(),\n      index: tokenStream.tokenIndex,\n      // TODO: remove it, temporary solution\n      balance: tokenStream.balance[tokenStream.tokenIndex],\n      // TODO: remove it, temporary solution\n      node: currentNode\n    });\n    tokenStream.next(); // console.log({ ...tokens[tokens.length - 1], node: undefined });\n  }\n\n  return tokens;\n}\n\nmodule.exports = function (value, syntax) {\n  if (typeof value === 'string') {\n    return prepareTokens(value, null);\n  }\n\n  return syntax.generate(value, astToTokens);\n};","map":{"version":3,"sources":["/Users/macbook/Documents/GitHub/React 3/billing-app/node_modules/react-pdf-html/node_modules/css-tree/lib/lexer/prepare-tokens.js"],"names":["tokenize","require","TokenStream","tokenStream","astToTokens","decorator","handlers","curNode","prev","len","node","nodes","buffer","children","tmp","call","chunk","push","length","result","prepareTokens","str","tokens","nodesOffset","nodesIndex","currentNode","eof","tokenStart","type","tokenType","value","getTokenValue","index","tokenIndex","balance","next","module","exports","syntax","generate"],"mappings":"AAAA,IAAIA,QAAQ,GAAGC,OAAO,CAAC,cAAD,CAAtB;;AACA,IAAIC,WAAW,GAAGD,OAAO,CAAC,uBAAD,CAAzB;;AACA,IAAIE,WAAW,GAAG,IAAID,WAAJ,EAAlB;AACA,IAAIE,WAAW,GAAG;AACdC,EAAAA,SAAS,EAAE,UAASC,QAAT,EAAmB;AAC1B,QAAIC,OAAO,GAAG,IAAd;AACA,QAAIC,IAAI,GAAG;AAAEC,MAAAA,GAAG,EAAE,CAAP;AAAUC,MAAAA,IAAI,EAAE;AAAhB,KAAX;AACA,QAAIC,KAAK,GAAG,CAACH,IAAD,CAAZ;AACA,QAAII,MAAM,GAAG,EAAb;AAEA,WAAO;AACHC,MAAAA,QAAQ,EAAEP,QAAQ,CAACO,QADhB;AAEHH,MAAAA,IAAI,EAAE,UAASA,IAAT,EAAe;AACjB,YAAII,GAAG,GAAGP,OAAV;AACAA,QAAAA,OAAO,GAAGG,IAAV;AACAJ,QAAAA,QAAQ,CAACI,IAAT,CAAcK,IAAd,CAAmB,IAAnB,EAAyBL,IAAzB;AACAH,QAAAA,OAAO,GAAGO,GAAV;AACH,OAPE;AAQHE,MAAAA,KAAK,EAAE,UAASA,KAAT,EAAgB;AACnBJ,QAAAA,MAAM,IAAII,KAAV;;AACA,YAAIR,IAAI,CAACE,IAAL,KAAcH,OAAlB,EAA2B;AACvBI,UAAAA,KAAK,CAACM,IAAN,CAAW;AACPR,YAAAA,GAAG,EAAEO,KAAK,CAACE,MADJ;AAEPR,YAAAA,IAAI,EAAEH;AAFC,WAAX;AAIH,SALD,MAKO;AACHC,UAAAA,IAAI,CAACC,GAAL,IAAYO,KAAK,CAACE,MAAlB;AACH;AACJ,OAlBE;AAmBHC,MAAAA,MAAM,EAAE,YAAW;AACf,eAAOC,aAAa,CAACR,MAAD,EAASD,KAAT,CAApB;AACH;AArBE,KAAP;AAuBH;AA9Ba,CAAlB;;AAiCA,SAASS,aAAT,CAAuBC,GAAvB,EAA4BV,KAA5B,EAAmC;AAC/B,MAAIW,MAAM,GAAG,EAAb;AACA,MAAIC,WAAW,GAAG,CAAlB;AACA,MAAIC,UAAU,GAAG,CAAjB;AACA,MAAIC,WAAW,GAAGd,KAAK,GAAGA,KAAK,CAACa,UAAD,CAAL,CAAkBd,IAArB,GAA4B,IAAnD;AAEAV,EAAAA,QAAQ,CAACqB,GAAD,EAAMlB,WAAN,CAAR;;AAEA,SAAO,CAACA,WAAW,CAACuB,GAApB,EAAyB;AACrB,QAAIf,KAAJ,EAAW;AACP,aAAOa,UAAU,GAAGb,KAAK,CAACO,MAAnB,IAA6BK,WAAW,GAAGZ,KAAK,CAACa,UAAD,CAAL,CAAkBf,GAAhC,IAAuCN,WAAW,CAACwB,UAAvF,EAAmG;AAC/FJ,QAAAA,WAAW,IAAIZ,KAAK,CAACa,UAAU,EAAX,CAAL,CAAoBf,GAAnC;AACAgB,QAAAA,WAAW,GAAGd,KAAK,CAACa,UAAD,CAAL,CAAkBd,IAAhC;AACH;AACJ;;AAEDY,IAAAA,MAAM,CAACL,IAAP,CAAY;AACRW,MAAAA,IAAI,EAAEzB,WAAW,CAAC0B,SADV;AAERC,MAAAA,KAAK,EAAE3B,WAAW,CAAC4B,aAAZ,EAFC;AAGRC,MAAAA,KAAK,EAAE7B,WAAW,CAAC8B,UAHX;AAGuB;AAC/BC,MAAAA,OAAO,EAAE/B,WAAW,CAAC+B,OAAZ,CAAoB/B,WAAW,CAAC8B,UAAhC,CAJD;AAI8C;AACtDvB,MAAAA,IAAI,EAAEe;AALE,KAAZ;AAOAtB,IAAAA,WAAW,CAACgC,IAAZ,GAfqB,CAgBrB;AACH;;AAED,SAAOb,MAAP;AACH;;AAEDc,MAAM,CAACC,OAAP,GAAiB,UAASP,KAAT,EAAgBQ,MAAhB,EAAwB;AACrC,MAAI,OAAOR,KAAP,KAAiB,QAArB,EAA+B;AAC3B,WAAOV,aAAa,CAACU,KAAD,EAAQ,IAAR,CAApB;AACH;;AAED,SAAOQ,MAAM,CAACC,QAAP,CAAgBT,KAAhB,EAAuB1B,WAAvB,CAAP;AACH,CAND","sourcesContent":["var tokenize = require('../tokenizer');\nvar TokenStream = require('../common/TokenStream');\nvar tokenStream = new TokenStream();\nvar astToTokens = {\n    decorator: function(handlers) {\n        var curNode = null;\n        var prev = { len: 0, node: null };\n        var nodes = [prev];\n        var buffer = '';\n\n        return {\n            children: handlers.children,\n            node: function(node) {\n                var tmp = curNode;\n                curNode = node;\n                handlers.node.call(this, node);\n                curNode = tmp;\n            },\n            chunk: function(chunk) {\n                buffer += chunk;\n                if (prev.node !== curNode) {\n                    nodes.push({\n                        len: chunk.length,\n                        node: curNode\n                    });\n                } else {\n                    prev.len += chunk.length;\n                }\n            },\n            result: function() {\n                return prepareTokens(buffer, nodes);\n            }\n        };\n    }\n};\n\nfunction prepareTokens(str, nodes) {\n    var tokens = [];\n    var nodesOffset = 0;\n    var nodesIndex = 0;\n    var currentNode = nodes ? nodes[nodesIndex].node : null;\n\n    tokenize(str, tokenStream);\n\n    while (!tokenStream.eof) {\n        if (nodes) {\n            while (nodesIndex < nodes.length && nodesOffset + nodes[nodesIndex].len <= tokenStream.tokenStart) {\n                nodesOffset += nodes[nodesIndex++].len;\n                currentNode = nodes[nodesIndex].node;\n            }\n        }\n\n        tokens.push({\n            type: tokenStream.tokenType,\n            value: tokenStream.getTokenValue(),\n            index: tokenStream.tokenIndex, // TODO: remove it, temporary solution\n            balance: tokenStream.balance[tokenStream.tokenIndex], // TODO: remove it, temporary solution\n            node: currentNode\n        });\n        tokenStream.next();\n        // console.log({ ...tokens[tokens.length - 1], node: undefined });\n    }\n\n    return tokens;\n}\n\nmodule.exports = function(value, syntax) {\n    if (typeof value === 'string') {\n        return prepareTokens(value, null);\n    }\n\n    return syntax.generate(value, astToTokens);\n};\n"]},"metadata":{},"sourceType":"script"}